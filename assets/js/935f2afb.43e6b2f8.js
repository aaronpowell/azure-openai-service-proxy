"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Azure OpenAI Proxy Service","href":"/azure-openai-service-proxy/","docId":"Introduction"},{"type":"category","label":"Service installation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"OpenAI proxy service","href":"/azure-openai-service-proxy/service-installation/OpenAI-Proxy","docId":"service-installation/OpenAI-Proxy"},{"type":"link","label":"Scaling the Proxy Service","href":"/azure-openai-service-proxy/service-installation/scaling-proxy-service","docId":"service-installation/scaling-proxy-service"},{"type":"category","label":"Testing","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Proxy service","href":"/azure-openai-service-proxy/service-installation/testing/testing","docId":"service-installation/testing/testing"},{"type":"link","label":"Load testing","href":"/azure-openai-service-proxy/service-installation/testing/load-testing","docId":"service-installation/testing/load-testing"}],"href":"/azure-openai-service-proxy/category/testing"}],"href":"/azure-openai-service-proxy/category/service-installation"},{"type":"link","label":"Playground installation","href":"/azure-openai-service-proxy/playground-installation","docId":"playground-installation"},{"type":"category","label":"Authorisation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Event authorization","href":"/azure-openai-service-proxy/Authorization/authorisation","docId":"Authorization/authorisation"},{"type":"link","label":"Adding an event code","href":"/azure-openai-service-proxy/Authorization/adding-event","docId":"Authorization/adding-event"}],"href":"/azure-openai-service-proxy/category/authorisation"},{"type":"link","label":"OpenAI model deployments","href":"/azure-openai-service-proxy/openai-deployments","docId":"openai-deployments"},{"type":"category","label":"Rate limits","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Azure OpenAI rate limits","href":"/azure-openai-service-proxy/rate-limits/openai-rate-limits","docId":"rate-limits/openai-rate-limits"},{"type":"link","label":"Proxy service rate limits","href":"/azure-openai-service-proxy/rate-limits/proxy-rate-limits","docId":"rate-limits/proxy-rate-limits"}],"href":"/azure-openai-service-proxy/category/rate-limits"},{"type":"link","label":"Using the Playground","href":"/azure-openai-service-proxy/playground","docId":"playground"},{"type":"link","label":"OpenAI API access","href":"/azure-openai-service-proxy/raw-openai-api-access","docId":"raw-openai-api-access"}]},"docs":{"Authorization/adding-event":{"id":"Authorization/adding-event","title":"Adding an event code","description":"For now, you add an event via the Azure Storage Account Storage browser. The Storage browser is available in the Azure Portal, under the Storage account resource.","sidebar":"tutorialSidebar"},"Authorization/authorisation":{"id":"Authorization/authorisation","title":"Event authorization","description":"Access to the proxy service endpoint is controlled by an event code. The proxy service is accessible when the current UTC is between the StartUTC and the EndUTC times and the event is active. The event code is passed in the openai-event-code header. If the event code is not passed, or the event code is not active, or the current UTC is not between the StartUTC and the EndUTC times, the proxy service will return a 401 unauthorized error.","sidebar":"tutorialSidebar"},"Introduction":{"id":"Introduction","title":"Azure OpenAI Proxy Service","description":"<Social","sidebar":"tutorialSidebar"},"openai-deployments":{"id":"openai-deployments","title":"OpenAI model deployments","description":"From the Azure Portal, select the Azure OpenAI resource, then select the Deployments tab, and finally select Create deployment. Enter a friendly name for the deployment, and select the model and the capacity. The capacity is the number of requests per minute. The capacity can be changed at any time. The deployment will take a few minutes to provision.","sidebar":"tutorialSidebar"},"playground":{"id":"playground","title":"Using the Playground","description":"The Playground is a web-based application that allows users to experiment with OpenAI Chat Completions.","sidebar":"tutorialSidebar"},"playground-installation":{"id":"playground-installation","title":"Playground installation","description":"tbd","sidebar":"tutorialSidebar"},"rate-limits/openai-rate-limits":{"id":"rate-limits/openai-rate-limits","title":"Azure OpenAI rate limits","description":"Azure OpenAI model deployments have two limits, the first being tokens per minute, and the second being requests per minute. You are most likely to hit the Tokens per minute limit especially as you scale up the number of users using the system.","sidebar":"tutorialSidebar"},"rate-limits/proxy-rate-limits":{"id":"rate-limits/proxy-rate-limits","title":"Proxy service rate limits","description":"The proxy service access is rate limited to balance access to the raw REST APIs to allow fair access for all users.","sidebar":"tutorialSidebar"},"raw-openai-api-access":{"id":"raw-openai-api-access","title":"OpenAI API access","description":"The Azure OpenAI proxy service provides access to the Azure OpenAI APIs for developers to build applications, again using a time bound event code. Initially there are two REST endpoints available via the proxy, chat completion, and embeddings.","sidebar":"tutorialSidebar"},"service-installation/OpenAI-Proxy":{"id":"service-installation/OpenAI-Proxy","title":"OpenAI proxy service","description":"The solution consists of two parts, a proxy service, and a web client with a similar look and feel to the official Azure OpenAI Playground. The proxy service is a Python FastAPI app that proxies requests to the OpenAI API.","sidebar":"tutorialSidebar"},"service-installation/scaling-proxy-service":{"id":"service-installation/scaling-proxy-service","title":"Scaling the Proxy Service","description":"The proxy service is stateless, so scales vertically and horizontally. The proxy serviceis designed to auto-scale up and down using Azure Container Apps replicas. The proxy service is configured to scale up to 10 replicas. The number of replicas can be changed from the Azure Portal or from the az cli. For example, to scale to 30 replicas using the az cli, change the:","sidebar":"tutorialSidebar"},"service-installation/testing/load-testing":{"id":"service-installation/testing/load-testing","title":"Load testing","description":"There are several load testing tools available. The recommended tool is JMeter as the test plan can be deployed to Azure. The JMeter test plan is located in the loadtest folder. The test plan is configured to run 100 concurrent users, generating 4 requests per minute.","sidebar":"tutorialSidebar"},"service-installation/testing/testing":{"id":"service-installation/testing/testing","title":"Proxy service","description":"There are various options to test the endpoint. The simplest is to use Curl from either PowerShell or a Bash/zsh terminal. For example:","sidebar":"tutorialSidebar"}}}')}}]);